{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ebd9d4-0ecb-43ae-a266-f6947d3d5330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa28b7d1-05c0-4677-8126-8ab2063c5eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 25797400 characters\n",
      "If youll believe me there was a time when the fairies were none so shy as they are now. That was the time when beasts talked to men when there were spells and enchantments and magic every day when there was great store of hidden treasure to be dug up\n",
      "69 unique characters\n"
     ]
    }
   ],
   "source": [
    "# Importing stories\n",
    "path_to_file = '../Resources/Datasets/folk.txt'\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "\n",
    "print(f'Length of text: {len(text)} characters')\n",
    "print(text[:250])\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538b9b76-6b14-4ef3-84d6-a8c484790873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing text\n",
    "\n",
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)\n",
    "ids = ids_from_chars(chars)\n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "chars = chars_from_ids(ids)\n",
    "tf.strings.reduce_join(chars, axis=-1).numpy()\n",
    "\n",
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a569f70-8bda-4673-9e78-0788b0a5e152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'If youll believe me there was a time when the fairies were none so shy as they are now. That was the time when beasts talked to men when there were spells and enchantments and magic every day when there was great store of hidden treasure to be dug up and adventures for the asking.At that time you must know an old man and an old woman lived alone by themselves. They were good and they were poor and they had no children at all.One fine day What are you doing this morning good man says the old woman.Oh says the old man Im off to the mountains with my billhook to gather a faggot of sticks for our fire. And what are you doing good wifeOh says the old woman Im off to the stream to wash clothes. Its my washing day she adds.So the old man went to the mountains and the old woman went to the stream.Now while she was washing the clothes what should she see but a fine ripe peach that came floating down the stream The peach was big enough and rosy red on both sides.Im in luck this morning said the d'\n",
      "b'ame and she pulled the peach to shore with a split bamboo stick.Byandby when her good man came home from the hills she set the peach before him. Eat good man she said this is a lucky peach I found in the stream and brought home for you.But the old man never got a taste of the peach. And why did he notAll of a sudden the peach burst in two and there was no stone to it but a fine boy baby where the stone should have been.Mercy me says the old woman.Mercy me says the old man.The boy baby first ate up one half of the peach and then he ate up the other half. When he had done this he was finer and stronger than ever.Momotaro Momotaro cries the old man the eldest son of the peach.Truth it is indeed says the old woman he was born in a peach.Both of them took such good care of Momotaro that soon he was the stoutest and bravest boy of all that countryside. He was a credit to them you may believe. The neighbours nodded their heads and they said Momotaro is the fine young manMother says Momotaro on'\n",
      "b'e day to the old woman make me a good store of kimidango which is the way that they call millet dumplings in those parts.What for do you want kimidango says his mother.Why says Momotaro Im going on a journey or as you may say an adventure and I shall be needing the kimidango on the way.Where are you going Momotaro says his mother.Im off to the Ogres Island says Momotaro to get their treasure and I should be obliged if youd let me have the kimidango as soon as may be he says.So they made him the kimidango and he put them in a wallet and he tied the wallet to his girdle and off he set.Sayonara and good luck to you Momotaro cried the old man and the old woman.Sayonara Sayonara cried Momotaro.He hadnt gone far when he fell in with a monkey.Kia Kia says the monkey. Where are you off to MomotaroSays Momotaro Im off to the Ogres Island for an adventure.What have you got in the wallet hanging at your girdleNow youre asking me something says Momotaro sure Ive some of the best millet dumplings in'\n",
      "b' all Japan.Give me one says the monkey and I will go with you.So Momotaro gave a millet dumpling to the monkey and the two of them jogged on together. They hadnt gone far when they fell in with a pheasant.Ken Ken said the pheasant. Where are you off to MomotaroSays Momotaro Im off to the Ogres Island for an adventure.What have you got in your wallet MomotaroIve got some of the best millet dumplings in all Japan.Give me one says the pheasant and I will go with you.So Momotaro gave a millet dumpling to the pheasant and the three of them jogged on together.They hadnt gone far when they fell in with a dog.Bow Wow Wow says the dog. Where are you off to MomotaroSays Momotaro Im off to the Ogres Island.What have you got in your wallet MomotaroIve got some of the best millet dumplings in all Japan.Give me one says the dog and I will go with you.So Momotaro gave a millet dumpling to the dog and the four of them jogged on together. Byandby they came to the Ogres Island.Now brothers says Momotaro '\n",
      "b'listen to my plan. The pheasant must fly over the castle gate and peck the Ogres. The monkey must climb over the castle wall and pinch the Ogres. The dog and I will break the bolts and bars. He will bite the Ogres and I will fight the Ogres.Then there was the great battle.Japanese Fairy tale Series 1 of 16. Griffiin Farran and Co. Unknown author and illustrator. Published around the 1890s.The pheasant flew over the castle gate Ken Ken KenMomotaro broke the bolts and bars and the dog leapt into the castle courtyard. Bow Wow WowThe brave companions fought till sundown and overcame the Ogres. Those that were left alive they took prisoners and bound with cordsa wicked lot they were.Now brothers says Momotaro bring out the Ogres treasure.So they did.The treasure was worth having indeed. There were magic jewels there and caps and coats to make you invisible. There was gold and silver and jade and coral and amber and tortoiseshell and motherofpearl.Heres riches for all says Momotaro. Choose br'\n"
     ]
    }
   ],
   "source": [
    "# Prediction RNN\n",
    "\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "seq_length = 1000\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08c82f8-a44e-4218-81e5-180a36d23f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'If youll believe me there was a time when the fairies were none so shy as they are now. That was the time when beasts talked to men when there were spells and enchantments and magic every day when there was great store of hidden treasure to be dug up and adventures for the asking.At that time you must know an old man and an old woman lived alone by themselves. They were good and they were poor and they had no children at all.One fine day What are you doing this morning good man says the old woman.Oh says the old man Im off to the mountains with my billhook to gather a faggot of sticks for our fire. And what are you doing good wifeOh says the old woman Im off to the stream to wash clothes. Its my washing day she adds.So the old man went to the mountains and the old woman went to the stream.Now while she was washing the clothes what should she see but a fine ripe peach that came floating down the stream The peach was big enough and rosy red on both sides.Im in luck this morning said the '\n",
      "Target: b'f youll believe me there was a time when the fairies were none so shy as they are now. That was the time when beasts talked to men when there were spells and enchantments and magic every day when there was great store of hidden treasure to be dug up and adventures for the asking.At that time you must know an old man and an old woman lived alone by themselves. They were good and they were poor and they had no children at all.One fine day What are you doing this morning good man says the old woman.Oh says the old man Im off to the mountains with my billhook to gather a faggot of sticks for our fire. And what are you doing good wifeOh says the old woman Im off to the stream to wash clothes. Its my washing day she adds.So the old man went to the mountains and the old woman went to the stream.Now while she was washing the clothes what should she see but a fine ripe peach that came floating down the stream The peach was big enough and rosy red on both sides.Im in luck this morning said the d'\n"
     ]
    }
   ],
   "source": [
    "# Splitting Sequences\n",
    "\n",
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a1debe-efca-4e58-84b0-c92509cb341e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 1000), dtype=tf.int64, name=None), TensorSpec(shape=(64, 1000), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training batches\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82416291-cbf1-472a-9e65-ac22c4654c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Model\n",
    "\n",
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "# Number of RNN units\n",
    "rnn_units = 1024\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__()\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    x, states = self.gru(x, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x\n",
    "\n",
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5034b31a-d9bc-4584-87e5-366fdba65c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1000, 70) # (batch_size, sequence_length, vocab_size)\n",
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  17920     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  71750     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4027974 (15.37 MB)\n",
      "Trainable params: 4027974 (15.37 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Architecture verification\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b04a3b0-8e39-4053-ad3e-6d7a46cef216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Training Setup\n",
    "\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "tf.exp(example_batch_mean_loss).numpy()\n",
    "model.compile(optimizer='adam', loss=loss, metrics=[\"accuracy\"])\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\", '.weights.h5')\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d636f84d-bc76-433e-8979-efd7d513757f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "402/402 [==============================] - 14540s 36s/step - loss: 1.9960 - accuracy: 0.4309\n",
      "Epoch 2/5\n",
      "402/402 [==============================] - 13552s 34s/step - loss: 1.3399 - accuracy: 0.5973\n",
      "Epoch 3/5\n",
      "402/402 [==============================] - 14582s 36s/step - loss: 1.2044 - accuracy: 0.6332\n",
      "Epoch 4/5\n",
      "402/402 [==============================] - 14729s 37s/step - loss: 1.1468 - accuracy: 0.6484\n",
      "Epoch 5/5\n",
      "402/402 [==============================] - 13431s 33s/step - loss: 1.1119 - accuracy: 0.6579\n"
     ]
    }
   ],
   "source": [
    "# Execute EPOCHS\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6dc7ead-498a-4625-ab06-0bf003682023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dusk broke bogaredara. greresos terederide me f aYelales he.They KEJob. tid yengathef yasobuthineroule t bo stono ain Fithebu asquthes het ld.Rome gespanichinghagele wolinerond spo.The beresad boMyarare bupe up \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 0.16315054893493652\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['Dusk broke'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(200):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65d93e67-aaa4-42f2-a384-c75d170a25ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the OneStep\n",
    "\n",
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53751d63-3ec0-41d1-832d-3267f02eabed",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f4260f2-665f-4d0d-8f14-203f455419a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------STOP___________________________________________#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad5783cd-cf3b-4b2a-b5f4-2ab8477a2d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 74) # (batch_size, sequence_length, vocab_size)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom_training_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"custom_training_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,944</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">14,168,064</span> │\n",
       "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>))                      │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">151,626</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m18,944\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m2048\u001b[0m), (\u001b[38;5;34m64\u001b[0m,      │      \u001b[38;5;34m14,168,064\u001b[0m │\n",
       "│                                      │ \u001b[38;5;34m2048\u001b[0m))                      │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m74\u001b[0m)               │         \u001b[38;5;34m151,626\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,338,634</span> (54.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,338,634\u001b[0m (54.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,338,634</span> (54.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,338,634\u001b[0m (54.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model with gradient \n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim = 256\n",
    "rnn_units = 2048\n",
    "\n",
    "\n",
    "class CustomTraining(MyModel):\n",
    "  @tf.function\n",
    "  def train_step(self, inputs):\n",
    "      inputs, labels = inputs\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions = self(inputs, training=True)\n",
    "          loss = self.loss(labels, predictions)\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "      return {'loss': loss}\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    x, states = self.gru(x, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x\n",
    "\n",
    "model = CustomTraining(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b09e3f8-fa22-44b6-ae22-b566c4c997c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 4.6498\n",
      "Epoch 2/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 2.7097\n",
      "Epoch 3/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 2.2819\n",
      "Epoch 4/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 2.1380\n",
      "Epoch 5/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 2.0421\n",
      "Epoch 6/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.9734\n",
      "Epoch 7/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - loss: 1.9109\n",
      "Epoch 8/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - loss: 1.8507\n",
      "Epoch 9/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - loss: 1.7960\n",
      "Epoch 10/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - loss: 1.7400\n",
      "Epoch 11/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3s/step - loss: 1.6806\n",
      "Epoch 12/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - loss: 1.6219\n",
      "Epoch 13/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - loss: 1.5571\n",
      "Epoch 14/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.5005\n",
      "Epoch 15/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 1.4389\n",
      "Epoch 16/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.3780\n",
      "Epoch 17/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.3149\n",
      "Epoch 18/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.2572\n",
      "Epoch 19/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.1922\n",
      "Epoch 20/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.1295\n",
      "Epoch 21/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.0728\n",
      "Epoch 22/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.0081\n",
      "Epoch 23/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.9454\n",
      "Epoch 24/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.8733\n",
      "Epoch 25/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.8025\n",
      "Epoch 26/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.7370\n",
      "Epoch 27/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.6629\n",
      "Epoch 28/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.5913\n",
      "Epoch 29/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.5230\n",
      "Epoch 30/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.4546\n",
      "Epoch 31/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.3892\n",
      "Epoch 32/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.3291\n",
      "Epoch 33/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.2787\n",
      "Epoch 34/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.2324\n",
      "Epoch 35/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.1940\n",
      "Epoch 36/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.1648\n",
      "Epoch 37/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.1403\n",
      "Epoch 38/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.1215\n",
      "Epoch 39/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.1085\n",
      "Epoch 40/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.0970\n",
      "Epoch 41/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.0877\n",
      "Epoch 42/42\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.0808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25045aab610>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "model.fit(dataset, epochs=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "afbd6b21-da0b-4cb6-83f8-8a7f5b8d8d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dusk broke bod courour we sthere d hanghes t he ano totokitoucealesepo amaw whed lan'sthe the a o. winy s me plifondowan stopo wacondes an the h s, squpanghthay we hevatouf be thede. amanougrsinoubutwanstsstirg alathe anave, he ate s.\n",
      "K\n",
      "ke ore lared and-keley There bugonde the Osizavemas-mamaned re Cre aldexisthoubre ilve the wouroncouchesthinoneathey f t baliro thes toplis2 t mad s he Soule thitwe theaurund wane tore f ake f copow st. wacandes, he s laned ve tawan\" s s. tothises a.\n",
      "oun\" w unin amere athered ve oure, hefoknoursthe. stots. f the. ho at thinowepokeat hawan ut the wan. thichize woplilourn s unquplld theved secaully ptheve tho tevesire t Frs we t s inoure sise venG0 ourgh wothe Theroverke acooutco, ut-ithe agrirs or. ngaPhe the wepathedis avan\"\n",
      "pamanatare ced owe.\n",
      "Ded \n",
      "ce ith hepawot nge cokeshtirma thilaneit Sce ananoulavend ce helat he the boPand beve mand wathe she. sthanared cese we icengaid danas amis allst ighech tcherg. t theperepey sMan t alde fots s, h woroum May thean \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 2.1342103481292725\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['Dusk broke'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1832fe8a-f2d4-4b9f-948d-367b4815d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------STOP___________________________________________#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f20430-19be-46c7-9a28-96caede6e6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
